Content		Topic
[Applause] okay [Applause] great great uh so thank you guys so um what I uh thought we were talk about today is uh basically start to look look at the question of like what does an ideal future for the ethereum lar 2 ecosystem look like right so uh what are the things that uh if we build um over the next few years then um you know we actually will have uh 2 ecosystem that like really has all of the properties that I think you know people are looking for and you look where we actually get something that really feels like what feels like what we wanted once we were when uh you know we were starting this uh whole journey of thinking about how to scale ethereum nearly 10 years ago right so ethereum ler 2 is today right so uh ethereum has a lot of ler 2os right I uh I still remember back in 2020 when there were still like maybe a couple of them and then after that there were like five of them and it's like okay you know we understand this I you know there's like you know there's optimism there's arbitrum there's polygon there's starware land and then there's zyink and like you know ethereum's got it five 2 the whole thing makes sense and then a year later it's like okay wow there's like a whole bunch of them and now it's you know people are starting to say that there's a know too many layer two teams at this point uh so know I feel like know the ecosystem has made a huge amount of progress um also uh starting to so I think the next thing to that we want to make a make progress on is like you know not the quantity of Layer Two is but the quality of them right and uh one of the most important metrics of quality is like basically the the security right so this is a page from El to beat and the stages right stage zero stage one stage two basically tell you like to what extent is this roll up like actually something that's secure and trustless and like actually protected by the proof system versus stage zero which is just a multisig right and like up until about a year ago literally everything was just a multi right except for I think fuel um was uh stage two the whole time but Fuel and dgate those are not evm rollups they're not general purpose rollups right they just are like serving a much more specific set of applications and I think like I think fuel has a programming model to some degree but it's like definitely not know close to evm right and uh as of about a month ago optimism has become a stage one rollup so it's kind of halfway there from being adjust a multisig to being fully trustless and so we now have two evm rollups that are within that category and uh that and both of them have plans to really start moving towards stage two over time right and uh you know dydx and ZK sync and uh there's a lot of others that are following suit right so I'm uh looking forward to you know the day when kak Rod can also join the list so you know hopefully that's going to come pretty soon so a lot of uh basic I think you know the trajectory on uh quality of rollups is definitely going in a really good direction right so the the big problems that I think we have today are one is security and trustless this right basically uh you know l2s uh like actually being l2s and not just being multisig um 7day withdrawal delay this is just for uh the optimistic ones right if you're an optimistic rollup you need to have some level of delay to uh ensure that if something wrong happened then someone is able to push a fraud proof in uh to uh stop the wrong thing from being finalized in the case of ZK rollups the finality time is uh already much shorter right so uh in the case of starkware I believe you know Bates are submitted like usually on the order of like about one every hour or so right um so it's like already definitely getting there but to me the ideal is not even an hour right to me the ideal is like for what is 12 seconds right or or even 4 seconds uh so I'll talk about some of the tricks that we can do to try to actually get there cross L2 transfers are difficult and like there's like a Galaxy brain um you know like combinatorial shared sequencing way to interpret that problem and like I actually don't even believe that's the number one priority to me this like isn't a math puzzle this is a a ux puzzle and you know we'll talk about some of those things as well smart contract while support difficults right so we're like actually starting to really make Headway on Smart contract wallets right so 5 years ago most people were just using um EAS these days like you know like like if you want to ask here right now right how many people here have a safe see lots of hands raised right so uh already a huge amount of progress um who here has or is a member of a multisig wallet that's not as safe okay see you soon but so see lots of multisig adoption right and know at the same time we've been starting to see a growth in know both like sponsored transactions like batched operations a lot of other things um and uh we now have you know EIP 7702 which is going to get us this like very smooth path by which the kind of account abstraction for ux space and you know the account abstraction for security space can basically kind of proceed further along the same trajectory and so you know we don't get these of two separate ecosystems then uh so a lot of progress right but the challenge is like onay the cross layer 2 support is not great right like there's uh leer twos that have uh incompatible um enshrine to can abstraction standards there's also justif effects that like if you have a multi and that multisig exists on different l2s and you want to change the keys you have like separately change the key on every L2 so a lot of annoying things like that centralized sequencing is uh one of the other big bottlenecks in terms of security andural dis right so uh you know we uh like the point of the ethereum ecosystem is not that like everyone just talks to servers right the you know we want to be able to have like actually decentralized applications and that's uh something that you know we've had on layer one but on Layer Two uh you know there's not enough rollups that are there so you know Tao has a based uh you know is a based rollup and so you know I think uh it's good that that exists and I would love to see more either based rollups or decentralized sequencing Solutions or both uh so the goal in one sentence right so I think that's kind of if you zoom into the issues right if you kind of zoom out to you know like what are we trying to accomplish I think uh one of the ways that I think about it is that you know using the greater ethereum verse should not feel like you're using 40 different blockchains right it should feel like you're using ethereum so what we want is we want something that has uh the fees of ethereum in 2015 and that has the and that feels like you're using ethereum in 2015 but that has the scalability and the level of ethereum in 2029 and that has the ux quality of ethereum in 2029 right and so basically the question is like how do we actually get there so I think um from a ux side I kind of just wants to actually skip ahead a bit and like change the order around right so this is uh something I tweeted out a couple of days ago right so uh the experience depositing to poly market today right basically so poly Market is uh as you know the name implies on polygon and uh on uh so if you deposit the poly Market you you get to this page where like there's an address and like if you want to deposit coins to it then like oh you know you have to select polygon as the network and not polygon ZK evm and then you know you have to make sure and you like deposit your funds and if you do it wrong then like your money get stuck right it's like uh you know imagine you know you're asking someone to like pay you your salary and uh you have to tell them like no no no my bank is JP Morgan it's not Morgan and Chase it's JP Morgan those are toally different and if you get itong then like $100,000 disappears right so so this is like where we are now right and like this is something that we really uh you know like have to move Beyond and so the uh thing and then even if you get past that whole problem there's the problem that like currently you know bridging is like considered this completely different operation from sending and you have to like Bridge through bridging protocols and like how does this even work right and so what things should look like right is uh so there's a ERC 3770 which makes um which basically puts the name of the chain um in like into the address and so here basically it will just have one page that just says deposit deposit uscc to this address and the address just is um you know like whatever the whatever the name of the chain is colon and and then whatever the address inside the chain chain is and then you'd be able to copy that and then you would be able to just like put that straight into the two field of uh your of your browser wallet and then you'd put that straight in there and then it would click Send and if you already have coins on the same layer 2 it would just send those coins if you don't have coins on the layer 2 it would just automatically send them through some kind of cross layer 2 bridging protocol right so if we do this then sending feels like sending regardless of whether you're sending within one way or two or whether you're sending a Crossway or twos and the whole experience basically feels the same way that everyone being on ethereum together in like 2015 to 2019 felt except you just have like uh you know the name of a network in front of an address and like people can kind of uh you know if they don't want to think about it they don't even have to think about it right so I think we can like actually get to this right but this is I know like why I'm basically saying like this is uh I mean this is like 10% like fancy math and figuring out synchronous combinatorial stuff and like 90% just like very basic ux issues so I think we can actually get to this right um so I think uh you know the question now is like basically you know like what are all of the other different pieces that really need to fit together to make the ler to ecosystem really be what we want it to be so let's talk about getting to stage two right so uh today we have rollups that are stage one and stage one basically means you have some kind of proof system the proof system can be optimistic can be ZK whichever one and then you could have a security Council and that Security Council is like basically a multisig and the multisig can go in and it can overturn the result with a 75% threshold right so you need s basically here if the proof system is is going doing right like if everything is fine in the proof system then you would need a 75% threshold of this group in order to take the money out um like maliciously and then if the proof system is wrong then you know basically as long like as long as 75% are still honest then like they would be able to like Bas go in and fix the bug right and like that difference between 50 and 75% is like actually pretty huge right like there actually have been some multi hacks like there was one of one hack where there was this uh like I think it was one of these like centralized like multi Bridges and I think it was like a a five out of nine and like literally five of the keys out of nine got hacked at the same time uh basically just because uh like a bunch of them were on the same computer right and like if that had been up to 34 threshold then like it seems very likely that the hack could not have happened right so I think so what stage two says is it basically goes further right stage two is like the first one the it's like the stage where you can actually say that it's trustless and the reason basically is that as long as the or the way that the stage two rules are designed is that as long as there are no bugs in the code the security Council has no power right so the way that stage two works is that the security Council only has power if the code provably disagrees with itself right and so how can the code Pro disagree with itself like one of the way one example would be that if someone submits basically like two different state routs and both of them with the same data and both of them pass the proof system right another one is like if no one submits a proof for a week right so like a liveness failure instead of a safety failure a third one is if you have two different proof systems and those proof systems disagree with each other right and and so you know here for example like in this diagram you know you could imagine like a two out of three between a ZK proof system an optimistic proof system and like in this case a four of seven Security Council and the security Council would only have the power to basically choose which one of the two is correct right so even if there's a bug like if if the ZK thing says a and the optimistic says b like the security Council can't just like go and say aha we have a bug and so now we're going to say it's C and we're going to take the money for ourselves right it's like no the security Council can only choose between a and right so this so multipro are one of the options and like this is something I've been talking about for a long time and like you know know optimism is getting into multipro Tao is getting into multipro so a lot of good uh good work happening on that another one is uh formal verification um so uh you know there's a increasing amount of work starting in figur kind of for figuring out how to uh formally verify an entire know ZK evm verification Pipeline and within starware and kakarat land I know there you know there has been a formalization of Cairo and you know Cairo has been kind of like that that's been fully know like ends to end proven as I understand know like even including the you know the arithmetization um and basically yeah I know the goal is to try to like extend this to zek avms right and uh it's starting to feel like the most uh viable route to doing this basically is to just kind of like piggyback off of an arithmetization of something simple so either risk five or Cairo and then uh you basically like formally verify the evm in that and then you have a you formally verify aover of milk chyro or risk 5 and then you basically have it right and then if we have that then like you get this like very strong Assurance like in the actual technology itself right and at some point like there becomes much less pointed having five different proving systems if you can just prove that those five different proving systems like actually are proving things that are all isomorphic to each other right so that's one big part and so now let's talk about how do we get from Seven uh from seven day will all times to four second all times right so 7day going down to 1 hour is easy right you just you know switch from optimistic to ZK going down from 1 hour to one slat that's the challenging thing right and so there's two challenges that that both have to be solved the first challenge is that ZK evm proofs today they take a long time they've been improving a lot right like I still remember like one or two years ago when uh the an average case proof of an ethereum block would take 5 hours and then today it's you know you have like average case proof uh proofs of an ethereum block that are like 20 minutes and then the worst case is like only a few times more than that right um and uh there are things that we can do like either like I mean on an L1 but then in this case you only have to do it on an L2 like kick out catch I can replace it with a better hash function increase the gas cost of some pre compiles I know do a couple of other things right and you can get rid of the worst case but then you know the average case still takes like 20 minutes right and uh the the basic reason why is that ZK proven currently is not parallelizable enough right basically you know you have one machine that one machine is doing all of the proving and so Z proving like inevitably has an overhead of like you know a factor of 100 to a th000 compared to regular computation and the problem is that if that overhead is all happening on one machine then like that turns into a factor increase in time right like one second turns into a th seconds so in order to get past this like the easiest way to do this that we know how to do already is to parallelize right basically what you do is so first you know you have an evm block uh verification computation then you have an arithmetization which could be some kind of direct arithmetization or you could like basically stick an evm Runner into Cairo or risk 5 and then you just basically have like a very compact virtual machine that just executes for like 10 million steps and then inside of that virtual machine what you then do is you split the proving into pieces right you basically take your 10 million chyo steps and then you split them up into a th pieces and then you have a th pieces Each of which have 10,000 chyro steps right and then for each one of those you just separately make a proof and then each one of those is only like 1,000th of the process of uh verifying an entire ethereum block and so you can make a proof for each one of those pieces in a second and then you make up for that by just like having lots of machines and then this is like like in theory not too hard to do if you know how to do like devops magic in like AWS or whatever right or or you just like get uh you know get a thousand like gpus yourself or like you just like I don't know you know like hope that the AI like the AI bubble is going to pop soon or something but uh you know like if that doesn't happen then you know there's there's there's still I mean actually if it doesn't pop there's like that just means there's going to be even more compute right and so you just like like like if you can parallelize you're fine right and then once you have your proofs then basically you have an aggregation tree you know you take like two of the proofs turn them into like make one proof of those two proofs or realistically you could even go like four to one or like 8 to one or whatever right and then you make a proof of the proofs make a proof of the proofs make a proof of the proofs so then you have one proof right and like theoretically there's like basically none of this relies on any like any kind of fundamental discoveries that we don't have right like this is something that if you can parallelize enough you can like do something with present day technology that can prove ethereum blocks in real time right in less than one slot right like uh recursive proofs I you know there's been numbers that you can do that in I think like 170 milliseconds in blany 3 um so it's uh the basically the challenge is like not fundamental the challenges like these kind of technical things right basically one of the biggest issues is basically if you're going to like have this proof over a lot of chyo steps then like how do you actually like Stitch all of the different proofs together right and there's like easy ways to do it which is just like you put the entire um you know like like state of the VM into a Merkel tree um and there's possibly more complex ways as well but like this is uh you know one of the things that we still uh like still need to like think through how to optimize right but like this is the uh end goal right and if we get to this end goal than one of the big hurdles in like basically having ZK rollups that commit every slot is going to be solved the other hurdle is we need onchain proof aggregation right so the big reason why you know like something like Star doesn't commit more frequently is because a proof has a high overhead you know it's like something something like 1 to five million gas and like you don't want to be paying 1 to 5 billion gas every slot and like realistically you know if you like both you know starw land and optimism and arbitrum and polygon and like three other ecosystems all committing every SWAT then that's already enough to just like fully fill the an ethereum block right and so the way that I think we need to solve this problem is basically with onchain um with proof aggregation mechanisms right so basically you imagine you have like a bunch of different ruup ecosystems that all submit a proof and then offchain you just basically have a mol the proofs go into the mol and then you have one actor that gathers the proofs and then turns the proofs into a uh a single aggregate proof of the proofs and then just like puts that aggregate proof of the proofs into a block right so this is uh something where like it's basically just an engineering task to like actually to actually build something like this but if you do then the economics of every individual roll up publishing much more frequently are going going to start to actually become much more viable right and then what kind of proof scheme does it make sense to use for this kind of like ultimate Pro of all proofs I think realistically yeah you want something that has maximum security and minimal assumptions and what does that mean that basically means you know like Starks with uh the parameters you know like set so that you have you know like unconditionally provable 128bit security right so that's uh like this is also something that I think can really uh help push the L2 ecosystem forward so talked about cross L2 transfers key store rollups another one of those interesting topics right basically yeah like you can have a role you can have an account where that account and like the logic of that account lives in one place but then you can spend from anywhere right and so you could have a safe the logic of the safe lives from one place you can update your safe in one place and then you can spend on ne2 and when you spend on ne2 you're basically like real time creating a proof of the uh of your state on uh you know like wherever your account lives right and there's like an easy way and a hard way to do this the easy way to do this is your account still lives on layer one and uh now that layer one is cheap like this is uh starting to become more doable right and like if we uh and so there's uh like basically if you want to do this then the main property that the layer 2 needs to have is it needs to be able to directly read layer one right so this is something that optimism has this is something that scroll is uh is doing and this is something where I think there's starting to be work in trying to standardize one or a couple of versions of this into an rip I and so this would be amazing if you have and then the more complex version is you basically put this the uh state of your account into one L2 and then you just use like cross L2 Branch proving to Pro uh to prove it into anywhere else right so um sequencing um so uh status quo basically rollups are doing sequencing themselves um and I think there's like two possible Futures here right under kind of the uh more L1 minimalist version and the more L1 maximalist version the more L1 minimalist version basically says um rollups just end up doing decentralized sequencing themselves and like that could be some kind of shared sequencing it could be every every L2 doing on its own or something and then the other future is that L1 gets somewhat faster confirmations and um then you just get more based rollups right and so if if a rollup is just based so it just uh basically does sequencing by just accepting submissions from anyone then like that's just like a much more decentralized architecture that you get for free right so like these are you know like some of the Big Technical um directions that I find valuable right but then like what do we get yet as a result of implementing all of these things right and to me like I come back to like the vision in one sentence right the vision in one sentence is basically you want something that has the fees of ethereum in 2015 which means that like you basically free like regular transactions for under a cent you want something that feels like ethereum in 2015 right which basically means that like it just feels like you're sending coins between addresses and like you're doing calls between addresses but where at the same time you have the scalability and the ux of the Year 2029 right so you have so you have something that is ultra cheap but is serving a really huge number of users and where under the hood it's this complicated you know like asynchronous layer 2 um Centric ecosystem where you have like a whole bunch of these different layer 2 universes that have various different properties but from a user's point of view it just looks like you're sending things from ethereum addresses to other ethereum addresses so 100K plus TPS across the ethereum ecosystem I actually think you know we're going to be able to get even higher than that especially if you include you know like plasmas and offchain da things in that list fast performance applications with a high level of decentralization trustless and sensorship resistance which to your on is much less visible to a user but I think it also should not be completely invisible like I think the difference between security models matter right and users should see you know like are they interacting with something on a secure ecosystem or they interacting with uh something on a less secure ecosystem um and uh basically you know you get the kind of advantages that we had you know in ethereum as a small ecosystem and the advantages of this like highly developed and highly performant big ecosystem at the same time right so I think that's the uh ultimate goal and then on top of that obviously uh you know like Ultra fast uh uh transactions right so basically you know from a user point of view like you should be able to get like for applications that need it you should be able to get a confirmation within a couple of seconds or even within one second right and uh you know obviously 2015 ethereum like if you send a transaction often it would take like 5 minutes to confirm um so I think if we get to all of these things then like we get to an ethereum ecosystem that like really has really amazing ux right and like any like fragmentation problems end up you know not being visible to users and to a user it just looks like you're working with ethereum and at the same time we actually have amazing scalability and we have all of this amazing layer 2 I know roll up enabled Innovation uh continuing to happen um under the hood and you know at the same time uh we actually get to this some kind of Singularity where the where from a security perspective like the the level of robustness like actually starts increasing and we actually get to the point where we're like more confident in the security of every layer of of the stack where than we were at any point in our history so I hope that we can all work together to get there thank you [Applause] thank you sorry um we have time for a few questions okay uh so um I'm Li from I'm from tallos and we're also currently working on a protocol that is decentralized recursive proof aggregation I think all these look wonderful the question to ask is that when are we going to get this m when someone builds it I think is the answer again I think like no like technologically we're not far away from any of this stuff right like you know like we can uh literally do like 600,000 uh you know like Poseidon hashes per second on an M3 laptop now right so I think it's uh like this is the big difference between now and three years ago which is that like now there aren't any fundamental research questions that are stopping this from being possible now it's just like implementation standardization and like having the thing in some kind of form factor that's that that makes it actually usable for people so which means we've overcome the research and development stage and then what would be the timeline like that's uh you know that's not my job that's uh that that's your guys's job okay then second question second question is not relevant to ziki I just want to dive into your bring and understand um in the last crypto cycle nft was the one increased and then for the cycle what do you foresee would be then coming I mean I think the the applications that we've seen like become you know the mo the most uh uniquely successful this time I mean uh one is the whole decentralized social space um two um would be poly Market um three would be just continued Pro just like people using crypto for payments in like especially just like personto person International payments in all kinds of contexts um yeah I I I feel like those are like I mean three of the of the bigger ones and then there's like a long tale of uh various other other things that are continuing to grow as well thanks okay so we have four questions please keep the questions like one sentence thanks vitalic for your speech and uh it was uh quite abstract oops sorry mhm quite abstract touching the whole ethereum ecosystem uh but could you tell us a bit more about your connection with Kakarot and uh why why did you choose this yeah I mean I think I mean I've been uh you know I mean first of all just been a big fan of the uh starkware ecosystems you know work on Starks and doing taking this uh you know really uh rigorous job of just like valuing and pushing forward on the technology and kakarat been a really crucial part of that by building a zkm on top of the technology um and so I I see it as you know being definitely you know one of the most advanced uh efforts at build at building a zkm which is valuable both for the uh the ler you know any kind of evm layer 2 um and eventually for layer one as well um so I think all of these things are like that that entire stack you know including the kakarat code itself including Cairo and uh including Stark technology as just uh you know it's it's a great Tech and I think there's uh a lot of uh value in that continuing to improve hey thanks for your talk um quick question you mentioned uh reading the L1 from the L2 what do you think of the approach to have the rout Ash available on L2 um with a cheap proof wouldn't that solve the the issue um yeah um so I think there's like some strengths and weaknesses of that route right so if you just have the root hash I mean the strength is that it's just much easier to implement right because uh like you I mean l2s need to have access to L1 hashes anyway because you need to have infrastructure to accept deposits right and so you basically just like piggy back off of the exact same infrastructure and you just make the hash accessible the weakness is that you don't get like synchronous reading ability right so like if you zoom into the key store roll of use case what basically or basically what you have have is right like you have uh like let's say you have a safe on an L2 and then in like normally when you have a safe the safe when you get a transaction it verifies the signature and then it does an operation right to verify signature you have to verify it against the public key and like normally today the public key just like lives in the same place right if you do reading then like you just take the public key and you you put the public key on on L1 instead right and so if you have um like actual like state reading like either like either L1 SL Lo or like L1 evm call if you have either of those right then like you're basically able to replicate that exact same workflow um and and uh well whereas if you only have state rout access then the challenge is like basically you're going to have like that transaction is going to have to like include some kind of ZK snark of a proof and like you basically have to like build a whole bunch of ler 2 infrastructure you have to worry about the possibility that like you send a transaction and then the root change and the proof is outdated so like you know you basically you get your like you know like like base level Simplicity but you end up paying for that in like a lot of account level complexity yes hello with Al so I had my my question was in the upcoming future do you see we would have few rollups like high capacity rollups bringing the whole 100K TPS Vision or do you think that the future will be where every application has its own roll up and then we discover abstractions to make them talk I I feel like so far it's been like mostly the second right though uh I mean I expect what we're going to see is we're going to see yeah like especially out of the larger application like some of them will have their own ler some of them will be like on one of the general purpose layer and then smaller applications they'll just be on some kind of larger L2 and then you know we'll see some kind of split between rollups and validium right where I think uh rollups make more sense for like higher value Financial stuff and uh validium make sense for like anything that just doesn't require quite that security level and is okay with lower fees right so like anything like games for example like a lot of social stuff should be either of validium or even some other structure um so I expect we're going to continue to see a mi hey vitalic uh thanks for the talk um a lot of your slides were kind of for evm rollups um and part of the rollup Centric road map was to explore different execution environments how do you think we keep the same ux and standardization across different execution environments what do we need to do yeah I think uh like I think we need to have kind of like a concentric circle of like different tiers of Standards right basically where even if you're not being like exactly evm equivalent there's like different I me know like common layers that you can still agree on and you can still get like a lot of the same benefits right so like if you think of like ERC 3770 for example right like if the equos system standardized around that then like that has no dependencies on like any specific VM architecture or like even signature scheme or anything whatsoever right so that's uh like that's one example of a standard that like actually would make life easier for nonm rollups because it helps us move away from the world where we assume that you have the same address on every chain because like having the same address on every chain is like a big I know like killer for any kind of el2 that wants to experiment with VMS right then another piece of this is uh four key store um rollups then uh like if you do if you take the uh design where you know you actually you know like have uh the like public key stored in one place and then you can like read then like that becomes very friendly to having uh a lot of different VMS right uh because uh if you take the current approach which is like you have a copy of a safe everywhere then like you can't have a copy off on things that are that are non evm um then yeah like I think like moving moving away from the norm that like having the same address on different chains is like something we strive for I think I mean for smart contract wellet like that's just like basically mandatory um then I in terms of uh other standards like standards for moving standards for moving assets between chains so like something like 7683 like I think you can like I feel like even in its current form it's like pretty close to something that's uh that non evm chains interoperate with um so I think we just have to like look at it standard by uh by standard but I think there's uh like there's still a lot of things that even nonm chains can agree on cool thanks everyone so we're going to take a small break and move to the next uh panel which is discussion about the Cambrian explosion of rollups and how to navigate this trade-off and design space [Applause]		ethereum, decentralized, crypto, nft, protocol, wallet

